{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aabee45d-cd3a-427e-b336-0d8e2b1fd86d",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b83ed-0c48-4189-bf08-21116ad2f522",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a97d12-eb02-48fb-a659-1d123354ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ce2f63-22ec-4485-aab0-895bda419a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ozerozdal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    " \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e352973-79d5-44d5-ba5c-501b4d4931ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus(df:pd.DataFrame, verbose=False) -> pd.DataFrame:\n",
    "    '''\n",
    "    Generates sparse matrix of corpus of words from the given reviews\n",
    "    and returns X and y\n",
    "    \n",
    "    inputs:\n",
    "        df -> pd.DataFrame() object containing reviews and likes\n",
    "        verbose --> bool whether would like to print the corpus sample\n",
    "        \n",
    "    outputs:\n",
    "        X -> np.array() object, which is a sparse matrix of corpus\n",
    "        y -> np.array() object of likes column in the original dataframe\n",
    "    '''\n",
    "    corpus = []\n",
    "    \n",
    "    # processing text\n",
    "    for i in range(0, df.shape[0]):\n",
    "        review = re.sub('[^a-zA-Z]', ' ', df.loc[i,'Review'])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        ps = PorterStemmer()\n",
    "        review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    \n",
    "    # printing the output\n",
    "    if verbose == True:\n",
    "        print('corpus  \\n')\n",
    "        print(pd.Series(corpus).sample(10))\n",
    "        print('')\n",
    "    \n",
    "    # Fitting and transforming the corpus with CountVectorizer()\n",
    "    count_vect = CountVectorizer(max_features=1500)\n",
    "    X = pd.DataFrame(count_vect.fit_transform(corpus).toarray())\n",
    "    y = df['Liked']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa666a1e-7471-4d6e-b3b4-5629305824cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, test_size=0.2, shuffle=True, random_state=0):\n",
    "    '''\n",
    "    Uses train_test_split function of sklearn library to split the dataset\n",
    "    \n",
    "    inputs:\n",
    "        X -> np.array() object, which is a sparse matrix of corpus \n",
    "        y -> np.array() object of likes column in the original dataframe\n",
    "        test_size -> float between 0 and 1\n",
    "        shuffle -> boolean object\n",
    "        stratisfy -> feature to base stratas on    \n",
    "        random_state -> integer\n",
    "    \n",
    "    outputs: X_train, y_train, X_test, y_test np.array() objects\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=shuffle, random_state=random_state)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e22028-fb11-4956-ab57-ebfff70560ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Fitting model and scoring'''\n",
    "def classification_model(X_train, y_train, X_test, y_test, model='LogisticRegression', save=False, graph=False, metrics:list=['accuracy_score'], **kwargs): # , rs=0\n",
    "    '''\n",
    "    Fits, saves, predicts, outputs performance and produces graphs for select classification model out of 'LogReg', 'KNN', 'SVC', 'SVC_rbf', 'NaiveBayes', 'tree' or 'forest'\n",
    " \n",
    "    inputs:\n",
    "        X_train -> nd array. X train values\n",
    "        y_train -> 1d array. y train values\n",
    "        X_test -> nd array. X test values\n",
    "        y_test -> 1d array. y test values.\n",
    "        model -> specify a model, LogReg by default. Enter string value from the above choice of models.\n",
    "        rs -> integer, 0 by default. Enter any integer value\n",
    "        save -> boolean, False by default. Enter True if you want to pickle the model\n",
    "        graph -> boolean, False by default. enter True if you want a graph\n",
    " \n",
    "    output:\n",
    "        perf_stats -> pd.DataFrame() object of selected performance statistics\n",
    "        cm -> confusion matrix\n",
    "    '''\n",
    " \n",
    "    # Instantiating model\n",
    "    mod = eval(model)(**kwargs)\n",
    "    \n",
    "    # Fitting models\n",
    "    mod.fit(X_train, y_train)\n",
    " \n",
    "    # Pikling model\n",
    "    if save == True:\n",
    "        joblib.dump(value=mod, filename=os.path.join(projDir, str(model)+'.pickle'))\n",
    " \n",
    "    # Model evaluation\n",
    "    y_pred = mod.predict(X_test)\n",
    "    perf = {i: eval(i)(y_test, y_pred) for i in metrics}\n",
    "    perf_stats = pd.Series(list(perf.values()), index=list(perf.keys()), name=model)\n",
    " \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = np.vstack((cm[1][::-1], cm[0][::-1]))\n",
    " \n",
    "    return perf_stats, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5701cc9-1c14-4791-b1f6-1fa98922252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ozerozdal/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        accuracy_score  precision_score  recall_score  \\\n",
      "LogisticRegression               0.660         0.906977      0.378641   \n",
      "KNeighborsClassifier             0.590         0.640000      0.466019   \n",
      "SVC                              0.740         0.892308      0.563107   \n",
      "SVC                              0.485         0.000000      0.000000   \n",
      "GaussianNB                       0.730         0.684211      0.883495   \n",
      "DecisionTreeClassifier           0.630         0.939394      0.300971   \n",
      "RandomForestClassifier           0.695         0.838710      0.504854   \n",
      "\n",
      "                        f1_score  \n",
      "LogisticRegression      0.534247  \n",
      "KNeighborsClassifier    0.539326  \n",
      "SVC                     0.690476  \n",
      "SVC                     0.000000  \n",
      "GaussianNB              0.771186  \n",
      "DecisionTreeClassifier  0.455882  \n",
      "RandomForestClassifier  0.630303  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    " \n",
    "    # Data prep\n",
    "    projDir = '/Users/ozerozdal/Documents/GitHub/Dive-Into-Machine-Learning/Natural Language Processing/Data'\n",
    "    datafile= os.path.join(projDir,'Restaurant_Reviews.tsv')\n",
    "    dataset = pd.read_csv(datafile, delimiter='\\t', quoting=3)\n",
    "    X, y = generate_corpus(df=dataset)\n",
    "    X_train, y_train, X_test, y_test = split_dataset(X, y)\n",
    " \n",
    "    # Classification model execution\n",
    "    logreg, _ = classification_model(X_train, y_train, X_test, y_test, model='LogisticRegression', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], penalty='l1', C=0.2, solver='liblinear', random_state=0, save=True)\n",
    " \n",
    "    KNN, _ = classification_model(X_train, y_train, X_test, y_test, model='KNeighborsClassifier', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], weights='distance', p=2)\n",
    " \n",
    "    svc, _ = classification_model(X_train, y_train, X_test, y_test, model='SVC', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], kernel='linear', random_state=0, gamma='auto', C=0.1)\n",
    " \n",
    "    svc_r, _ = classification_model(X_train, y_train, X_test, y_test, model='SVC', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], kernel='rbf', random_state=0, gamma='auto', C=0.1)\n",
    " \n",
    "    GNB, _ = classification_model(X_train, y_train, X_test, y_test, model='GaussianNB', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'])\n",
    " \n",
    "    tree, _ = classification_model(X_train, y_train, X_test, y_test, model='DecisionTreeClassifier', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], criterion='entropy', max_depth=5, random_state=0)\n",
    " \n",
    "    forest, _ = classification_model(X_train, y_train, X_test, y_test, model='RandomForestClassifier', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], n_estimators=22, criterion='entropy', random_state=0, max_depth=5)\n",
    " \n",
    "    print(pd.concat([logreg, KNN, svc, svc_r, GNB, tree, forest], axis=1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d27f1-0914-4584-870d-9b5b28992aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
