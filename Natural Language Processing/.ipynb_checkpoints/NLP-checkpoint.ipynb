{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aabee45d-cd3a-427e-b336-0d8e2b1fd86d",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b83ed-0c48-4189-bf08-21116ad2f522",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32a97d12-eb02-48fb-a659-1d123354ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35f507-5567-4e77-aa9c-4db7a216f3da",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa57d806-36b2-45db-86f7-8ab9c81a0b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b9cea-005b-4c60-bf46-d4ca38a43c58",
   "metadata": {},
   "source": [
    "## Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "733f8456-f56d-4e81-a41b-04e8016bbae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ozerozdal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae84a1d5-38ba-4cf9-8dea-a46c935ff6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wow love place', 'crust not good', 'not tasti textur nasti', 'stop late may bank holiday rick steve recommend love', 'select menu great price', 'get angri want damn pho', 'honeslti tast fresh', 'potato like rubber could tell made ahead time kept warmer', 'fri great', 'great touch', 'servic prompt', 'would not go back', 'cashier care ever say still end wayyy overpr', 'tri cape cod ravoli chicken cranberri mmmm', 'disgust pretti sure human hair', 'shock sign indic cash', 'highli recommend', 'waitress littl slow servic', 'place not worth time let alon vega', 'not like']\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f259a3d-8456-423c-b325-8f1c390bc7a8",
   "metadata": {},
   "source": [
    "## Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "304b7c6c-932a-4a97-b892-3efd76c72a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6bde1eaf-3835-4b40-83b8-14af343b08fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b2c783d-a4b5-47b6-91f6-3341357501ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1500)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9aebe-fa82-46c2-bfec-38f7a526f3b4",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "982a984f-c8b4-4aac-8f2f-f6f685b15e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b317c-f30c-4414-9f5d-9a69e35725d6",
   "metadata": {},
   "source": [
    "## Training the Naive Bayes model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40ade618-e5eb-4800-9cbb-64010d09a4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41433d72-4a92-4a82-a63b-f404d6a9ede1",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98157643-8c24-471d-bf93-57ca703573ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca36004-0ba7-4290-9371-e202171b1239",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10d31aae-7973-420e-acbf-a221ed420ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 42]\n",
      " [12 91]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a916c3a-2dda-427f-a5e2-c2ac09fda9f2",
   "metadata": {},
   "source": [
    "## Predicting if a single review is positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178effa-e9cb-48ba-8fc2-3af338371302",
   "metadata": {},
   "source": [
    "### Positive review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0fc60-eb4f-49ef-ae05-da1d48a5fba0",
   "metadata": {},
   "source": [
    "Use our model to predict if the following review:\n",
    "\n",
    "\"I love this restaurant so much\"\n",
    "\n",
    "is positive or negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c05e06-6b23-4a4f-bec9-e4129d9fe9c1",
   "metadata": {},
   "source": [
    "**Solution:** We just repeat the same text preprocessing process we did before, but this time with a single review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6006ae49-dd91-457b-9406-1ab740795d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "new_review = 'I love this restaurant so much'\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower()\n",
    "new_review = new_review.split()\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = ' '.join(new_review)\n",
    "new_corpus = [new_review]\n",
    "new_X_test = cv.transform(new_corpus).toarray()\n",
    "new_y_pred = classifier.predict(new_X_test)\n",
    "print(new_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1052cf-c362-4f97-b29e-0be6297a2e26",
   "metadata": {},
   "source": [
    "The review was correctly predicted as positive by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4b0f5-78bf-4771-ac00-24f739c3a26e",
   "metadata": {},
   "source": [
    "### Negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d7629-4214-47e7-90d3-a30420b5015f",
   "metadata": {},
   "source": [
    "Use our model to predict if the following review:\n",
    "\n",
    "\"I hate this restaurant so much\"\n",
    "\n",
    "is positive or negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a95cd1-8fec-48db-8507-b86a0c81ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = 'I hate this restaurant so much'\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower()\n",
    "new_review = new_review.split()\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = ' '.join(new_review)\n",
    "new_corpus = [new_review]\n",
    "new_X_test = cv.transform(new_corpus).toarray()\n",
    "new_y_pred = classifier.predict(new_X_test)\n",
    "print(new_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dde20e-19a4-42d8-bc88-c846f6204cbb",
   "metadata": {},
   "source": [
    "The review was correctly predicted as negative by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f56a2-5003-493a-87a7-21ca6c9dfaa2",
   "metadata": {},
   "source": [
    "# CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57ece144-5cc9-408e-9cbb-d905d065a2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.3-cp38-none-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from catboost) (3.3.4)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.4.0-py2.py3-none-any.whl (25.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3 MB 1.9 MB/s eta 0:00:01    |███████████▋                    | 9.2 MB 1.8 MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from catboost) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from catboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from catboost) (1.6.2)\n",
      "Requirement already satisfied: six in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from catboost) (1.15.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ozerozdal/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (8.2.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-1.0.3 graphviz-0.19 plotly-5.4.0 tenacity-8.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install catboost\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7545fda0-e3ff-4ef0-a74b-9da1da4a1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = cb.Pool(X_train, y_train) \n",
    "test_dataset = cb.Pool(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e99393b-6a38-481d-92a4-338d5fb3f954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6196911\ttotal: 2.55ms\tremaining: 247ms\n",
      "1:\tlearn: 0.5994645\ttotal: 5.15ms\tremaining: 247ms\n",
      "2:\tlearn: 0.5759395\ttotal: 7.07ms\tremaining: 224ms\n",
      "3:\tlearn: 0.5655650\ttotal: 9.21ms\tremaining: 216ms\n",
      "4:\tlearn: 0.5396076\ttotal: 11.3ms\tremaining: 210ms\n",
      "5:\tlearn: 0.5233041\ttotal: 13.3ms\tremaining: 204ms\n",
      "6:\tlearn: 0.5000068\ttotal: 15.4ms\tremaining: 200ms\n",
      "7:\tlearn: 0.4846394\ttotal: 17.5ms\tremaining: 197ms\n",
      "8:\tlearn: 0.4766777\ttotal: 19.5ms\tremaining: 193ms\n",
      "9:\tlearn: 0.4699433\ttotal: 21.4ms\tremaining: 189ms\n",
      "10:\tlearn: 0.4575408\ttotal: 23.5ms\tremaining: 186ms\n",
      "11:\tlearn: 0.4452534\ttotal: 25.5ms\tremaining: 183ms\n",
      "12:\tlearn: 0.4320429\ttotal: 27.4ms\tremaining: 179ms\n",
      "13:\tlearn: 0.4199770\ttotal: 29.2ms\tremaining: 175ms\n",
      "14:\tlearn: 0.4085807\ttotal: 31.2ms\tremaining: 173ms\n",
      "15:\tlearn: 0.3986089\ttotal: 33.2ms\tremaining: 170ms\n",
      "16:\tlearn: 0.3867744\ttotal: 35.3ms\tremaining: 168ms\n",
      "17:\tlearn: 0.3752469\ttotal: 37.2ms\tremaining: 165ms\n",
      "18:\tlearn: 0.3695267\ttotal: 39.1ms\tremaining: 163ms\n",
      "19:\tlearn: 0.3605341\ttotal: 41.3ms\tremaining: 161ms\n",
      "20:\tlearn: 0.3527870\ttotal: 43.2ms\tremaining: 158ms\n",
      "21:\tlearn: 0.3482993\ttotal: 45.2ms\tremaining: 156ms\n",
      "22:\tlearn: 0.3437826\ttotal: 47ms\tremaining: 153ms\n",
      "23:\tlearn: 0.3333497\ttotal: 48.9ms\tremaining: 151ms\n",
      "24:\tlearn: 0.3299953\ttotal: 50.9ms\tremaining: 148ms\n",
      "25:\tlearn: 0.3230643\ttotal: 52.7ms\tremaining: 146ms\n",
      "26:\tlearn: 0.3178146\ttotal: 54.7ms\tremaining: 144ms\n",
      "27:\tlearn: 0.3130753\ttotal: 56.6ms\tremaining: 142ms\n",
      "28:\tlearn: 0.3081893\ttotal: 58.9ms\tremaining: 140ms\n",
      "29:\tlearn: 0.3049160\ttotal: 60.7ms\tremaining: 138ms\n",
      "30:\tlearn: 0.3003777\ttotal: 62.7ms\tremaining: 136ms\n",
      "31:\tlearn: 0.2969019\ttotal: 64.7ms\tremaining: 134ms\n",
      "32:\tlearn: 0.2934018\ttotal: 66.6ms\tremaining: 131ms\n",
      "33:\tlearn: 0.2879807\ttotal: 68.4ms\tremaining: 129ms\n",
      "34:\tlearn: 0.2858456\ttotal: 70.4ms\tremaining: 127ms\n",
      "35:\tlearn: 0.2828060\ttotal: 72.5ms\tremaining: 125ms\n",
      "36:\tlearn: 0.2786631\ttotal: 74.5ms\tremaining: 123ms\n",
      "37:\tlearn: 0.2740835\ttotal: 76.4ms\tremaining: 121ms\n",
      "38:\tlearn: 0.2708208\ttotal: 78.2ms\tremaining: 118ms\n",
      "39:\tlearn: 0.2656497\ttotal: 80.2ms\tremaining: 116ms\n",
      "40:\tlearn: 0.2633059\ttotal: 81.9ms\tremaining: 114ms\n",
      "41:\tlearn: 0.2614656\ttotal: 83.5ms\tremaining: 111ms\n",
      "42:\tlearn: 0.2596019\ttotal: 85.4ms\tremaining: 109ms\n",
      "43:\tlearn: 0.2571492\ttotal: 87.3ms\tremaining: 107ms\n",
      "44:\tlearn: 0.2503900\ttotal: 89ms\tremaining: 105ms\n",
      "45:\tlearn: 0.2464961\ttotal: 90.6ms\tremaining: 102ms\n",
      "46:\tlearn: 0.2437186\ttotal: 92.3ms\tremaining: 100ms\n",
      "47:\tlearn: 0.2417973\ttotal: 94ms\tremaining: 97.9ms\n",
      "48:\tlearn: 0.2400772\ttotal: 95.6ms\tremaining: 95.6ms\n",
      "49:\tlearn: 0.2383197\ttotal: 97.2ms\tremaining: 93.3ms\n",
      "50:\tlearn: 0.2363715\ttotal: 98.8ms\tremaining: 91.1ms\n",
      "51:\tlearn: 0.2348264\ttotal: 100ms\tremaining: 88.8ms\n",
      "52:\tlearn: 0.2328124\ttotal: 102ms\tremaining: 86.6ms\n",
      "53:\tlearn: 0.2317618\ttotal: 104ms\tremaining: 84.4ms\n",
      "54:\tlearn: 0.2299664\ttotal: 105ms\tremaining: 82.4ms\n",
      "55:\tlearn: 0.2267330\ttotal: 107ms\tremaining: 80.2ms\n",
      "56:\tlearn: 0.2243506\ttotal: 109ms\tremaining: 78.1ms\n",
      "57:\tlearn: 0.2231139\ttotal: 110ms\tremaining: 76.2ms\n",
      "58:\tlearn: 0.2221113\ttotal: 112ms\tremaining: 74.1ms\n",
      "59:\tlearn: 0.2183142\ttotal: 114ms\tremaining: 72.1ms\n",
      "60:\tlearn: 0.2176142\ttotal: 115ms\tremaining: 70ms\n",
      "61:\tlearn: 0.2159741\ttotal: 117ms\tremaining: 68ms\n",
      "62:\tlearn: 0.2088229\ttotal: 119ms\tremaining: 66.1ms\n",
      "63:\tlearn: 0.2076078\ttotal: 121ms\tremaining: 64.1ms\n",
      "64:\tlearn: 0.2057122\ttotal: 123ms\tremaining: 62.2ms\n",
      "65:\tlearn: 0.2038468\ttotal: 124ms\tremaining: 60.3ms\n",
      "66:\tlearn: 0.2032745\ttotal: 126ms\tremaining: 58.3ms\n",
      "67:\tlearn: 0.2005205\ttotal: 128ms\tremaining: 56.3ms\n",
      "68:\tlearn: 0.1989038\ttotal: 129ms\tremaining: 54.3ms\n",
      "69:\tlearn: 0.1976684\ttotal: 131ms\tremaining: 52.4ms\n",
      "70:\tlearn: 0.1968050\ttotal: 133ms\tremaining: 50.4ms\n",
      "71:\tlearn: 0.1960715\ttotal: 134ms\tremaining: 48.5ms\n",
      "72:\tlearn: 0.1930387\ttotal: 136ms\tremaining: 46.5ms\n",
      "73:\tlearn: 0.1917741\ttotal: 137ms\tremaining: 44.6ms\n",
      "74:\tlearn: 0.1907577\ttotal: 139ms\tremaining: 42.6ms\n",
      "75:\tlearn: 0.1897805\ttotal: 141ms\tremaining: 40.7ms\n",
      "76:\tlearn: 0.1886040\ttotal: 142ms\tremaining: 38.8ms\n",
      "77:\tlearn: 0.1830010\ttotal: 144ms\tremaining: 36.9ms\n",
      "78:\tlearn: 0.1810068\ttotal: 146ms\tremaining: 35ms\n",
      "79:\tlearn: 0.1790354\ttotal: 147ms\tremaining: 33.1ms\n",
      "80:\tlearn: 0.1780475\ttotal: 149ms\tremaining: 31.3ms\n",
      "81:\tlearn: 0.1769578\ttotal: 151ms\tremaining: 29.4ms\n",
      "82:\tlearn: 0.1759081\ttotal: 152ms\tremaining: 27.5ms\n",
      "83:\tlearn: 0.1749212\ttotal: 154ms\tremaining: 25.7ms\n",
      "84:\tlearn: 0.1723787\ttotal: 156ms\tremaining: 23.8ms\n",
      "85:\tlearn: 0.1713918\ttotal: 157ms\tremaining: 22ms\n",
      "86:\tlearn: 0.1704069\ttotal: 159ms\tremaining: 20.1ms\n",
      "87:\tlearn: 0.1681148\ttotal: 161ms\tremaining: 18.2ms\n",
      "88:\tlearn: 0.1668365\ttotal: 162ms\tremaining: 16.4ms\n",
      "89:\tlearn: 0.1658186\ttotal: 164ms\tremaining: 14.6ms\n",
      "90:\tlearn: 0.1648606\ttotal: 165ms\tremaining: 12.7ms\n",
      "91:\tlearn: 0.1641338\ttotal: 167ms\tremaining: 10.9ms\n",
      "92:\tlearn: 0.1631638\ttotal: 169ms\tremaining: 9.08ms\n",
      "93:\tlearn: 0.1617339\ttotal: 170ms\tremaining: 7.25ms\n",
      "94:\tlearn: 0.1610150\ttotal: 172ms\tremaining: 5.43ms\n",
      "95:\tlearn: 0.1600173\ttotal: 174ms\tremaining: 3.62ms\n",
      "96:\tlearn: 0.1567682\ttotal: 176ms\tremaining: 1.81ms\n",
      "97:\tlearn: 0.1545616\ttotal: 177ms\tremaining: 0us\n",
      "\n",
      "========================================================\n",
      " Results from Random Search \n",
      "========================================================\n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " <catboost.core.CatBoostClassifier object at 0x7fba06e02ca0>\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.78125\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'depth': 4, 'iterations': 98, 'learning_rate': 0.6471990287990915}\n",
      "\n",
      " ========================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt  \n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "cat = CatBoostClassifier()\n",
    "parameters = {'depth'         : sp_randInt(4, 10),\n",
    "              'learning_rate' : sp_randFloat(),\n",
    "              'iterations'    : sp_randInt(10, 100)\n",
    "             }\n",
    "    \n",
    "randm = RandomizedSearchCV(estimator=cat, param_distributions = parameters, \n",
    "                               cv = 2, n_iter = 10, n_jobs=-1)\n",
    "randm.fit(X_train, y_train)\n",
    "\n",
    "# Results from Random Search\n",
    "print(\"\\n========================================================\")\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"========================================================\")    \n",
    "    \n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "        randm.best_estimator_)\n",
    "    \n",
    "print(\"\\n The best score across ALL searched params:\\n\",\n",
    "        randm.best_score_)\n",
    "    \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "        randm.best_params_)\n",
    "    \n",
    "print(\"\\n ========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8782bd78-8247-44bb-b84e-73d46696a7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = randm.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8141b458-c9d2-409b-b28e-15488df5eab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86 11]\n",
      " [33 70]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a195e11-7013-49b8-a416-c19cd90ae3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
