{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up\n",
    "Note that PyTorch also required a seed since we will be generating random tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f92c230ebb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(seed=SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "Some basics with PyTorch such as creating tensors and converting from common data structures (lists, arrays, etc.) to tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.0461,  0.4024, -1.0115],\n",
      "        [ 0.2167, -0.6123,  0.5036]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a random tensor\n",
    "x = torch.randn(2, 3) # normal distribution, (rand(2,3) -> uniform distribution)\n",
    "print(f\"Type: {x.type()}\")\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"Values: \\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Zero and Ones tensor\n",
    "x = torch.zeros(2, 3)\n",
    "print (x)\n",
    "x = torch.ones(2, 3)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# List → Tensor\n",
    "x = torch.Tensor([[1, 2, 3],[4, 5, 6]])\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"Values: \\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.1915, 0.6221, 0.4377],\n",
      "        [0.7854, 0.7800, 0.2726]])\n"
     ]
    }
   ],
   "source": [
    "# NumPy array → Tensor\n",
    "x = torch.Tensor(np.random.rand(2, 3))\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"Values: \\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# Changing tensor type\n",
    "x = torch.Tensor(3, 4)\n",
    "print(f\"Type: {x.type()}\")\n",
    "x = x.long()\n",
    "print(f\"Type: {x.type()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations\n",
    "Some basic operations with tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.0761, -0.6775, -0.3988],\n",
      "        [ 3.0633, -0.1589,  0.3514]])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "z = x + y\n",
    "print(f\"Size: {z.shape}\")\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 1.0796, -0.0759],\n",
      "        [ 1.2746, -0.5134]])\n"
     ]
    }
   ],
   "source": [
    "# Dot product\n",
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(3, 2)\n",
    "z = torch.mm(x, y)\n",
    "print(f\"Size: {z.shape}\")\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.8042, -0.1383,  0.3196],\n",
      "        [-1.0187, -1.3147,  2.5228]])\n",
      "Size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[ 0.8042, -1.0187],\n",
      "        [-0.1383, -1.3147],\n",
      "        [ 0.3196,  2.5228]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"Values: \\n{x}\")\n",
    "y = torch.t(x)\n",
    "print(f\"Size: {y.shape}\")\n",
    "print(f\"Values: \\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3, 4])\n",
      "x: \n",
      "tensor([[[ 1,  1,  1,  1],\n",
      "         [ 2,  2,  2,  2],\n",
      "         [ 3,  3,  3,  3]],\n",
      "\n",
      "        [[10, 10, 10, 10],\n",
      "         [20, 20, 20, 20],\n",
      "         [30, 30, 30, 30]]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 8])\n",
      "a: \n",
      "tensor([[ 1,  1,  1,  1,  2,  2,  2,  2],\n",
      "        [ 3,  3,  3,  3, 10, 10, 10, 10],\n",
      "        [20, 20, 20, 20, 30, 30, 30, 30]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 2, 4])\n",
      "b: \n",
      "tensor([[[ 1,  1,  1,  1],\n",
      "         [10, 10, 10, 10]],\n",
      "\n",
      "        [[ 2,  2,  2,  2],\n",
      "         [20, 20, 20, 20]],\n",
      "\n",
      "        [[ 3,  3,  3,  3],\n",
      "         [30, 30, 30, 30]]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 8])\n",
      "c: \n",
      "tensor([[ 1,  1,  1,  1, 10, 10, 10, 10],\n",
      "        [ 2,  2,  2,  2, 20, 20, 20, 20],\n",
      "        [ 3,  3,  3,  3, 30, 30, 30, 30]])\n"
     ]
    }
   ],
   "source": [
    "# Dangers of reshaping (unintended consequences)\n",
    "x = torch.tensor([\n",
    "    [[1,1,1,1], [2,2,2,2], [3,3,3,3]],\n",
    "    [[10,10,10,10], [20,20,20,20], [30,30,30,30]]\n",
    "])\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"x: \\n{x}\\n\")\n",
    "\n",
    "a = x.view(x.size(1), -1)\n",
    "print(f\"\\nSize: {a.shape}\")\n",
    "print(f\"a: \\n{a}\\n\")\n",
    "\n",
    "b = x.transpose(0,1).contiguous()\n",
    "print(f\"\\nSize: {b.shape}\")\n",
    "print(f\"b: \\n{b}\\n\")\n",
    "\n",
    "c = b.view(b.size(0), -1)\n",
    "print(f\"\\nSize: {c.shape}\")\n",
    "print(f\"c: \\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: \n",
      "tensor([[0.2111, 0.3372, 0.6638],\n",
      "        [1.0397, 1.8434, 0.6588]])\n",
      "Values: \n",
      "tensor([1.2508, 2.1805, 1.3226])\n",
      "Values: \n",
      "tensor([1.2120, 3.5418])\n"
     ]
    }
   ],
   "source": [
    "# Dimensional operations\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Values: \\n{x}\")\n",
    "y = torch.sum(x, dim=0) # add each row's value for every column\n",
    "print(f\"Values: \\n{y}\")\n",
    "z = torch.sum(x, dim=1) # add each columns's value for every row\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "How to extract, separate and join values from our tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "tensor([[-0.3449, -1.5447,  0.0685, -1.5104],\n",
      "        [-1.1706,  0.2259,  1.4696, -1.3284],\n",
      "        [ 1.9946, -0.8209,  1.0061, -1.0664]])\n",
      "x[:1]: \n",
      "tensor([[-0.3449, -1.5447,  0.0685, -1.5104]])\n",
      "x[:1, 1:3]: \n",
      "tensor([[-1.5447,  0.0685]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print (f\"x: \\n{x}\")\n",
    "print (f\"x[:1]: \\n{x[:1]}\")\n",
    "print (f\"x[:1, 1:3]: \\n{x[:1, 1:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: \n",
      "tensor([[-0.9505, -0.6567, -1.7232],\n",
      "        [-0.9854, -0.6118, -0.6743]])\n",
      "Values: \n",
      "tensor([[-0.9505, -1.7232],\n",
      "        [-0.9854, -0.6743]])\n",
      "Values: \n",
      "tensor([-0.9505, -0.6743])\n"
     ]
    }
   ],
   "source": [
    "# Select with dimensional indicies\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Values: \\n{x}\")\n",
    "\n",
    "col_indices = torch.LongTensor([0, 2])\n",
    "chosen = torch.index_select(x, dim=1, index=col_indices) # values from column 0 & 2\n",
    "print(f\"Values: \\n{chosen}\")\n",
    "\n",
    "row_indices = torch.LongTensor([0, 1])\n",
    "col_indices = torch.LongTensor([0, 2])\n",
    "chosen = x[row_indices, col_indices] # values from (0, 0) & (2, 1)\n",
    "print(f\"Values: \\n{chosen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: \n",
      "tensor([[-0.4455, -0.4108,  0.3571],\n",
      "        [-1.4713,  0.9365,  0.2561]])\n",
      "Values: \n",
      "tensor([[-0.4455, -0.4108,  0.3571],\n",
      "        [-1.4713,  0.9365,  0.2561],\n",
      "        [-0.4455, -0.4108,  0.3571],\n",
      "        [-1.4713,  0.9365,  0.2561]])\n",
      "Values: \n",
      "tensor([[-0.4455, -0.4108,  0.3571, -0.4455, -0.4108,  0.3571],\n",
      "        [-1.4713,  0.9365,  0.2561, -1.4713,  0.9365,  0.2561]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Values: \\n{x}\")\n",
    "y = torch.cat([x, x], dim=0) # stack by rows (dim=1 to stack by columns)\n",
    "print(f\"Values: \\n{y}\")\n",
    "z = torch.cat([x, x], dim=1) # stack by rows (dim=1 to stack by columns)\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients\n",
    "Let's determine gradients (rate of change) of our tensors with respect to their constituents using gradient bookkeeping. This is useful when we're training our models using backpropagation where we'll use these gradients to optimize our weights with the goals of lowering our objective function (loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "tensor([[0.7145, 0.5965, 0.0761, 0.1762],\n",
      "        [0.1008, 0.0073, 0.3606, 0.5587],\n",
      "        [0.0622, 0.0472, 0.5251, 0.3141]], requires_grad=True)\n",
      "x.grad: \n",
      "tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "# Tensors with gradient bookkeeping\n",
    "x = torch.rand(3, 4, requires_grad=True)\n",
    "y = 3*x + 2\n",
    "z = y.mean() # z = sum(y)/N where N = 12 in the example\n",
    "z.backward() # z has to be scalar\n",
    "print(f\"x: \\n{x}\")\n",
    "print(f\"x.grad: \\n{x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
