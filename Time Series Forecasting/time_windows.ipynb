{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5e799e-87d7-4d3d-bffc-903d9d17c2c0",
   "metadata": {},
   "source": [
    "# Time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6cd8575-b1d2-406d-91a0-597ae4205afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5c434-27de-4358-932b-d2765b32de06",
   "metadata": {},
   "source": [
    "First, we will train a model to forecast the next step given the previous 20 steps, therefore, we need to create a dataset of 20-step windows for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30b6f1cf-ccae-49a7-8af1-bd9e189d67c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.RangeDataset'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "print(type(dataset))\n",
    "print(type(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5514c8a-e0a2-471c-a695-5c882726a785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for val in dataset:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2332072-0022-42da-86de-053cecaa9efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for val in dataset:\n",
    "    print(val.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de0b85-7d19-4e84-9cb3-179456c3a503",
   "metadata": {},
   "source": [
    "# window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2af95cb-01ea-40e5-b437-4a272e55b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 \n",
      "1 2 3 4 5 \n",
      "2 3 4 5 6 \n",
      "3 4 5 6 7 \n",
      "4 5 6 7 8 \n",
      "5 6 7 8 9 \n",
      "6 7 8 9 \n",
      "7 8 9 \n",
      "8 9 \n",
      "9 \n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1)\n",
    "for window_dataset in dataset:\n",
    "    for val in window_dataset:\n",
    "        print(val.numpy(), end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687189df-4a24-4d5a-9bf2-ae48ae6ca764",
   "metadata": {},
   "source": [
    "# drop_remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5525176f-bb17-44b5-be70-6c907241909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 \n",
      "1 2 3 4 5 \n",
      "2 3 4 5 6 \n",
      "3 4 5 6 7 \n",
      "4 5 6 7 8 \n",
      "5 6 7 8 9 \n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "for window_dataset in dataset:\n",
    "    for val in window_dataset:\n",
    "        print(val.numpy(), end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad7aa740-aee8-409b-8ecf-b4f9df86c5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[1 2 3 4 5]\n",
      "[2 3 4 5 6]\n",
      "[3 4 5 6 7]\n",
      "[4 5 6 7 8]\n",
      "[5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# lambda function on every single dataset (windows) inside the nested dataset (dataset)\n",
    "# It takes five elements from a window and creates a tensor out of them.\n",
    "\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5)) #converts every single window dataset into a single tensor\n",
    "# The resulting dataset here is just a dataset that contains tensor of length five\n",
    "\n",
    "for window in dataset:\n",
    "    print(window.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "355dc290-3a6e-458c-adf8-89542d62b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3] [4]\n",
      "[1 2 3 4] [5]\n",
      "[2 3 4 5] [6]\n",
      "[3 4 5 6] [7]\n",
      "[4 5 6 7] [8]\n",
      "[5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1:])) # transforming dataset to convert each of windows into two tensors\n",
    "for x, y in dataset:\n",
    "    print(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efb34810-20f5-4a15-b639-9fde5786d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4] [5]\n",
      "[0 1 2 3] [4]\n",
      "[4 5 6 7] [8]\n",
      "[5 6 7 8] [9]\n",
      "[3 4 5 6] [7]\n",
      "[2 3 4 5] [6]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
    "dataset = dataset.shuffle(buffer_size=10) # shuffle the dataset\n",
    "for x, y in dataset:\n",
    "    print(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da91d32e-568e-4721-b028-4664cd913336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "y = [[5]\n",
      " [9]]\n",
      "x = [[4 5 6 7]\n",
      " [3 4 5 6]]\n",
      "y = [[8]\n",
      " [7]]\n",
      "x = [[2 3 4 5]\n",
      " [0 1 2 3]]\n",
      "y = [[6]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "dataset = dataset.batch(2).prefetch(1) #Creates batches of two windows\n",
    "# prefetch ensures that Tensorflow will load the next batch of data \n",
    "# while it's working on the current batch of data.\n",
    "\n",
    "for x, y in dataset:\n",
    "    print(\"x =\", x.numpy())\n",
    "    print(\"y =\", y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de2260aa-fd08-4f8d-ae3a-bf9edf28f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_dataset(series, window_size, batch_size=32,\n",
    "                   shuffle_buffer=1000):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f6934-c14d-4800-9010-4d2122c5f33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1a2d4-c70c-4fa7-8765-70564867cb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a4fa2-280f-479c-9f67-e03c8144003c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
